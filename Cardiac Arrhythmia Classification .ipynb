{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cardiac Arrhythmia Multy-Class Classification \n",
    "\n",
    "Analyze data and address missing data if there is any. \n",
    "\n",
    "Decide aboute a good evaluation strategy and justify choice. \n",
    "\n",
    "Find the best parameters for the following classification models: \n",
    "- KNN classifcation \n",
    "- Logistic Regression\n",
    "- Linear Supprt Vector Machine\n",
    "- Kerenilzed Support Vector Machine\n",
    "- Decision Tree\n",
    "- Random Forest \n",
    "\n",
    "Then use different bagging and boosting methods to boost the results\n",
    "\n",
    "Next, use data reduction method  learned in class to reduce the size of data, compare the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data=pd.read_csv(\"cardiac_arrhythmia.csv\", header=None, na_values = '?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>91</td>\n",
       "      <td>193</td>\n",
       "      <td>371</td>\n",
       "      <td>174</td>\n",
       "      <td>121</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>49.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>174</td>\n",
       "      <td>401</td>\n",
       "      <td>149</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>38.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>95</td>\n",
       "      <td>138</td>\n",
       "      <td>163</td>\n",
       "      <td>386</td>\n",
       "      <td>185</td>\n",
       "      <td>102</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "      <td>202</td>\n",
       "      <td>380</td>\n",
       "      <td>179</td>\n",
       "      <td>143</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>34.6</td>\n",
       "      <td>61.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "      <td>181</td>\n",
       "      <td>360</td>\n",
       "      <td>177</td>\n",
       "      <td>103</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>25.4</td>\n",
       "      <td>62.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   270   271  272  273  \\\n",
       "0   75    0  190   80   91  193  371  174  121  -16 ...   0.0   9.0 -0.9  0.0   \n",
       "1   56    1  165   64   81  174  401  149   39   25 ...   0.0   8.5  0.0  0.0   \n",
       "2   54    0  172   95  138  163  386  185  102   96 ...   0.0   9.5 -2.4  0.0   \n",
       "3   55    0  175   94  100  202  380  179  143   28 ...   0.0  12.2 -2.2  0.0   \n",
       "4   75    0  190   80   88  181  360  177  103  -16 ...   0.0  13.1 -3.6  0.0   \n",
       "\n",
       "   274  275  276   277   278  279  \n",
       "0    0  0.9  2.9  23.3  49.4    8  \n",
       "1    0  0.2  2.1  20.4  38.8    6  \n",
       "2    0  0.3  3.4  12.3  49.0   10  \n",
       "3    0  0.4  2.6  34.6  61.6    1  \n",
       "4    0 -0.1  3.9  25.4  62.8    7  \n",
       "\n",
       "[5 rows x 280 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452, 280)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 452 entries, 0 to 451\n",
      "Columns: 280 entries, 0 to 279\n",
      "dtypes: float64(121), int64(159)\n",
      "memory usage: 988.8 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>91</td>\n",
       "      <td>193</td>\n",
       "      <td>371</td>\n",
       "      <td>174</td>\n",
       "      <td>121</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>49.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>174</td>\n",
       "      <td>401</td>\n",
       "      <td>149</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>38.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>95</td>\n",
       "      <td>138</td>\n",
       "      <td>163</td>\n",
       "      <td>386</td>\n",
       "      <td>185</td>\n",
       "      <td>102</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "      <td>202</td>\n",
       "      <td>380</td>\n",
       "      <td>179</td>\n",
       "      <td>143</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>34.6</td>\n",
       "      <td>61.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "      <td>181</td>\n",
       "      <td>360</td>\n",
       "      <td>177</td>\n",
       "      <td>103</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>25.4</td>\n",
       "      <td>62.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   270   271  272  273  \\\n",
       "0   75    0  190   80   91  193  371  174  121  -16 ...   0.0   9.0 -0.9  0.0   \n",
       "1   56    1  165   64   81  174  401  149   39   25 ...   0.0   8.5  0.0  0.0   \n",
       "2   54    0  172   95  138  163  386  185  102   96 ...   0.0   9.5 -2.4  0.0   \n",
       "3   55    0  175   94  100  202  380  179  143   28 ...   0.0  12.2 -2.2  0.0   \n",
       "4   75    0  190   80   88  181  360  177  103  -16 ...   0.0  13.1 -3.6  0.0   \n",
       "\n",
       "   274  275  276   277   278  279  \n",
       "0    0  0.9  2.9  23.3  49.4    8  \n",
       "1    0  0.2  2.1  20.4  38.8    6  \n",
       "2    0  0.3  3.4  12.3  49.0   10  \n",
       "3    0  0.4  2.6  34.6  61.6    1  \n",
       "4    0 -0.1  3.9  25.4  62.8    7  \n",
       "\n",
       "[5 rows x 280 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>376</td>\n",
       "      <td>0.831858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22</td>\n",
       "      <td>0.048673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>0.017699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Total   Percent\n",
       "13    376  0.831858\n",
       "11     22  0.048673\n",
       "10      8  0.017699\n",
       "14      1  0.002212\n",
       "12      1  0.002212"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_total = data.isnull().sum().sort_values(ascending=False)\n",
    "miss_percent=(data.isnull().sum()/data.isnull().count()).sort_values(ascending=False)\n",
    "miss_data = pd.concat([miss_total, miss_percent], axis=1, keys=['Total', 'Percent'])\n",
    "miss_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(strategy='mean',axis=1) \n",
    "data=pd.DataFrame(imputer.fit_transform(data)).drop(13, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>49.4</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>38.8</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>34.6</td>\n",
       "      <td>61.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>25.4</td>\n",
       "      <td>62.8</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 279 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1      2     3      4      5      6      7      8     9    ...   270  \\\n",
       "0  75.0  0.0  190.0  80.0   91.0  193.0  371.0  174.0  121.0 -16.0  ...   0.0   \n",
       "1  56.0  1.0  165.0  64.0   81.0  174.0  401.0  149.0   39.0  25.0  ...   0.0   \n",
       "2  54.0  0.0  172.0  95.0  138.0  163.0  386.0  185.0  102.0  96.0  ...   0.0   \n",
       "3  55.0  0.0  175.0  94.0  100.0  202.0  380.0  179.0  143.0  28.0  ...   0.0   \n",
       "4  75.0  0.0  190.0  80.0   88.0  181.0  360.0  177.0  103.0 -16.0  ...   0.0   \n",
       "\n",
       "    271  272  273  274  275  276   277   278   279  \n",
       "0   9.0 -0.9  0.0  0.0  0.9  2.9  23.3  49.4   8.0  \n",
       "1   8.5  0.0  0.0  0.0  0.2  2.1  20.4  38.8   6.0  \n",
       "2   9.5 -2.4  0.0  0.0  0.3  3.4  12.3  49.0  10.0  \n",
       "3  12.2 -2.2  0.0  0.0  0.4  2.6  34.6  61.6   1.0  \n",
       "4  13.1 -3.6  0.0  0.0 -0.1  3.9  25.4  62.8   7.0  \n",
       "\n",
       "[5 rows x 279 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_indices = [0,1,2,3,4,5,6,7,8,9,10,11,12,14,278]\n",
    "new_names = [\"Age\", \"Sex\", \"Height\", \"Weight\",\"QRS duration\",\"P-R interval\",\"Q-T interval\",\"T interval\",\"P interval\",\"QRS\",\"T\",\"P\",\"QRST\",\"Heart rate\",\"Class\"]\n",
    "old_names = data.columns[column_indices]\n",
    "data.rename(columns=dict(zip(old_names, new_names)), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>QRS duration</th>\n",
       "      <th>P-R interval</th>\n",
       "      <th>Q-T interval</th>\n",
       "      <th>T interval</th>\n",
       "      <th>P interval</th>\n",
       "      <th>QRS</th>\n",
       "      <th>...</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>49.4</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>38.8</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>34.6</td>\n",
       "      <td>61.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>25.4</td>\n",
       "      <td>62.8</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 279 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Sex  Height  Weight  QRS duration  P-R interval  Q-T interval  \\\n",
       "0  75.0  0.0   190.0    80.0          91.0         193.0         371.0   \n",
       "1  56.0  1.0   165.0    64.0          81.0         174.0         401.0   \n",
       "2  54.0  0.0   172.0    95.0         138.0         163.0         386.0   \n",
       "3  55.0  0.0   175.0    94.0         100.0         202.0         380.0   \n",
       "4  75.0  0.0   190.0    80.0          88.0         181.0         360.0   \n",
       "\n",
       "   T interval  P interval   QRS  ...    270   271  272  273  274  275  276  \\\n",
       "0       174.0       121.0 -16.0  ...    0.0   9.0 -0.9  0.0  0.0  0.9  2.9   \n",
       "1       149.0        39.0  25.0  ...    0.0   8.5  0.0  0.0  0.0  0.2  2.1   \n",
       "2       185.0       102.0  96.0  ...    0.0   9.5 -2.4  0.0  0.0  0.3  3.4   \n",
       "3       179.0       143.0  28.0  ...    0.0  12.2 -2.2  0.0  0.0  0.4  2.6   \n",
       "4       177.0       103.0 -16.0  ...    0.0  13.1 -3.6  0.0  0.0 -0.1  3.9   \n",
       "\n",
       "    277   278  Class  \n",
       "0  23.3  49.4    8.0  \n",
       "1  20.4  38.8    6.0  \n",
       "2  12.3  49.0   10.0  \n",
       "3  34.6  61.6    1.0  \n",
       "4  25.4  62.8    7.0  \n",
       "\n",
       "[5 rows x 279 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T             0\n",
       "P             0\n",
       "QRST          0\n",
       "Heart rate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['T','P','QRST','Heart rate']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>QRS duration</th>\n",
       "      <th>P-R interval</th>\n",
       "      <th>Q-T interval</th>\n",
       "      <th>T interval</th>\n",
       "      <th>P interval</th>\n",
       "      <th>QRS</th>\n",
       "      <th>...</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.0</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>46.471239</td>\n",
       "      <td>0.550885</td>\n",
       "      <td>166.188053</td>\n",
       "      <td>68.170354</td>\n",
       "      <td>88.920354</td>\n",
       "      <td>155.152655</td>\n",
       "      <td>367.207965</td>\n",
       "      <td>169.949115</td>\n",
       "      <td>90.004425</td>\n",
       "      <td>33.676991</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.278982</td>\n",
       "      <td>9.048009</td>\n",
       "      <td>-1.457301</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.514823</td>\n",
       "      <td>1.222345</td>\n",
       "      <td>19.326106</td>\n",
       "      <td>29.473230</td>\n",
       "      <td>3.880531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.466631</td>\n",
       "      <td>0.497955</td>\n",
       "      <td>37.170340</td>\n",
       "      <td>16.590803</td>\n",
       "      <td>15.364394</td>\n",
       "      <td>44.842283</td>\n",
       "      <td>33.385421</td>\n",
       "      <td>35.633072</td>\n",
       "      <td>25.826643</td>\n",
       "      <td>45.431434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548876</td>\n",
       "      <td>3.472862</td>\n",
       "      <td>2.002430</td>\n",
       "      <td>0.050118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.347531</td>\n",
       "      <td>1.426052</td>\n",
       "      <td>13.503922</td>\n",
       "      <td>18.493927</td>\n",
       "      <td>4.407097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-172.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-28.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-44.200000</td>\n",
       "      <td>-38.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.425000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>-2.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>11.450000</td>\n",
       "      <td>17.550000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>27.900000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>25.825000</td>\n",
       "      <td>41.125000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>83.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>509.000000</td>\n",
       "      <td>381.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>88.800000</td>\n",
       "      <td>115.900000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 279 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age         Sex      Height      Weight  QRS duration  \\\n",
       "count  452.000000  452.000000  452.000000  452.000000    452.000000   \n",
       "mean    46.471239    0.550885  166.188053   68.170354     88.920354   \n",
       "std     16.466631    0.497955   37.170340   16.590803     15.364394   \n",
       "min      0.000000    0.000000  105.000000    6.000000     55.000000   \n",
       "25%     36.000000    0.000000  160.000000   59.000000     80.000000   \n",
       "50%     47.000000    1.000000  164.000000   68.000000     86.000000   \n",
       "75%     58.000000    1.000000  170.000000   79.000000     94.000000   \n",
       "max     83.000000    1.000000  780.000000  176.000000    188.000000   \n",
       "\n",
       "       P-R interval  Q-T interval  T interval  P interval         QRS  \\\n",
       "count    452.000000    452.000000  452.000000  452.000000  452.000000   \n",
       "mean     155.152655    367.207965  169.949115   90.004425   33.676991   \n",
       "std       44.842283     33.385421   35.633072   25.826643   45.431434   \n",
       "min        0.000000    232.000000  108.000000    0.000000 -172.000000   \n",
       "25%      142.000000    350.000000  148.000000   79.000000    3.750000   \n",
       "50%      157.000000    367.000000  162.000000   91.000000   40.000000   \n",
       "75%      175.000000    384.000000  179.000000  102.000000   66.000000   \n",
       "max      524.000000    509.000000  381.000000  205.000000  169.000000   \n",
       "\n",
       "          ...             270         271         272         273    274  \\\n",
       "count     ...      452.000000  452.000000  452.000000  452.000000  452.0   \n",
       "mean      ...       -0.278982    9.048009   -1.457301    0.003982    0.0   \n",
       "std       ...        0.548876    3.472862    2.002430    0.050118    0.0   \n",
       "min       ...       -4.100000    0.000000  -28.600000    0.000000    0.0   \n",
       "25%       ...       -0.425000    6.600000   -2.100000    0.000000    0.0   \n",
       "50%       ...        0.000000    8.800000   -1.100000    0.000000    0.0   \n",
       "75%       ...        0.000000   11.200000    0.000000    0.000000    0.0   \n",
       "max       ...        0.000000   23.600000    0.000000    0.800000    0.0   \n",
       "\n",
       "              275         276         277         278       Class  \n",
       "count  452.000000  452.000000  452.000000  452.000000  452.000000  \n",
       "mean     0.514823    1.222345   19.326106   29.473230    3.880531  \n",
       "std      0.347531    1.426052   13.503922   18.493927    4.407097  \n",
       "min     -0.800000   -6.000000  -44.200000  -38.600000    1.000000  \n",
       "25%      0.400000    0.500000   11.450000   17.550000    1.000000  \n",
       "50%      0.500000    1.350000   18.100000   27.900000    1.000000  \n",
       "75%      0.700000    2.100000   25.825000   41.125000    6.000000  \n",
       "max      2.400000    6.000000   88.800000  115.900000   16.000000  \n",
       "\n",
       "[8 rows x 279 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation strategy: Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>QRS duration</th>\n",
       "      <th>P-R interval</th>\n",
       "      <th>Q-T interval</th>\n",
       "      <th>T interval</th>\n",
       "      <th>P interval</th>\n",
       "      <th>QRS</th>\n",
       "      <th>...</th>\n",
       "      <th>269</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>...</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 278 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  Sex  Height  Weight  QRS duration  P-R interval  Q-T interval  \\\n",
       "Class                                                                       \n",
       "1.0    245  245     245     245           245           245           245   \n",
       "10.0    50   50      50      50            50            50            50   \n",
       "2.0     44   44      44      44            44            44            44   \n",
       "6.0     25   25      25      25            25            25            25   \n",
       "16.0    22   22      22      22            22            22            22   \n",
       "3.0     15   15      15      15            15            15            15   \n",
       "4.0     15   15      15      15            15            15            15   \n",
       "5.0     13   13      13      13            13            13            13   \n",
       "9.0      9    9       9       9             9             9             9   \n",
       "15.0     5    5       5       5             5             5             5   \n",
       "14.0     4    4       4       4             4             4             4   \n",
       "7.0      3    3       3       3             3             3             3   \n",
       "8.0      2    2       2       2             2             2             2   \n",
       "\n",
       "       T interval  P interval  QRS ...   269  270  271  272  273  274  275  \\\n",
       "Class                              ...                                       \n",
       "1.0           245         245  245 ...   245  245  245  245  245  245  245   \n",
       "10.0           50          50   50 ...    50   50   50   50   50   50   50   \n",
       "2.0            44          44   44 ...    44   44   44   44   44   44   44   \n",
       "6.0            25          25   25 ...    25   25   25   25   25   25   25   \n",
       "16.0           22          22   22 ...    22   22   22   22   22   22   22   \n",
       "3.0            15          15   15 ...    15   15   15   15   15   15   15   \n",
       "4.0            15          15   15 ...    15   15   15   15   15   15   15   \n",
       "5.0            13          13   13 ...    13   13   13   13   13   13   13   \n",
       "9.0             9           9    9 ...     9    9    9    9    9    9    9   \n",
       "15.0            5           5    5 ...     5    5    5    5    5    5    5   \n",
       "14.0            4           4    4 ...     4    4    4    4    4    4    4   \n",
       "7.0             3           3    3 ...     3    3    3    3    3    3    3   \n",
       "8.0             2           2    2 ...     2    2    2    2    2    2    2   \n",
       "\n",
       "       276  277  278  \n",
       "Class                 \n",
       "1.0    245  245  245  \n",
       "10.0    50   50   50  \n",
       "2.0     44   44   44  \n",
       "6.0     25   25   25  \n",
       "16.0    22   22   22  \n",
       "3.0     15   15   15  \n",
       "4.0     15   15   15  \n",
       "5.0     13   13   13  \n",
       "9.0      9    9    9  \n",
       "15.0     5    5    5  \n",
       "14.0     4    4    4  \n",
       "7.0      3    3    3  \n",
       "8.0      2    2    2  \n",
       "\n",
       "[13 rows x 278 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('Class').count().sort_values([278],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#There is imbalanced classes, so delete the class with observations less than 5\n",
    "# Choose Recall instead of accuracy as evaluation strategy, average = 'weighted'\n",
    "data = data[(data.Class != 7) & (data.Class != 8) & (data.Class != 14) & (data.Class != 15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438, 279)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model without PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "X_train_org, X_test_org, y_train, y_test = train_test_split(X, y, random_state=10)\n",
    "scaler=MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train_org)\n",
    "X_test=scaler.transform(X_test_org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. KNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [5, 10, 20, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(recall_score, average=weighted), verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import recall_score, make_scorer\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors':[5, 10, 20, 50]}\n",
    "recall_score=make_scorer(recall_score, average = 'weighted')\n",
    "score=make_scorer(recall_score, average = 'weighted')\n",
    "\n",
    "grid_search = GridSearchCV(knn , param_grid, cv = 5,scoring=recall_score,return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.012401</td>\n",
       "      <td>0.591463</td>\n",
       "      <td>0.641110</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.655039</td>\n",
       "      <td>0.573529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.637405</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>0.611321</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.647940</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.035909</td>\n",
       "      <td>0.016149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.011801</td>\n",
       "      <td>0.576220</td>\n",
       "      <td>0.585411</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_neighbors': 10}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.589147</td>\n",
       "      <td>0.573529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.576336</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>0.569811</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.591760</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.020829</td>\n",
       "      <td>0.010889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.012201</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.564846</td>\n",
       "      <td>20</td>\n",
       "      <td>{'n_neighbors': 20}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.544118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.561069</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>0.558491</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.561798</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.023971</td>\n",
       "      <td>0.005667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.013801</td>\n",
       "      <td>0.554878</td>\n",
       "      <td>0.554944</td>\n",
       "      <td>50</td>\n",
       "      <td>{'n_neighbors': 50}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.562016</td>\n",
       "      <td>0.544118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.557252</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.550943</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.546816</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.021765</td>\n",
       "      <td>0.005384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0         0.0036         0.012401         0.591463          0.641110   \n",
       "1         0.0032         0.011801         0.576220          0.585411   \n",
       "2         0.0032         0.012201         0.560976          0.564846   \n",
       "3         0.0040         0.013801         0.554878          0.554944   \n",
       "\n",
       "  param_n_neighbors               params  rank_test_score  split0_test_score  \\\n",
       "0                 5   {'n_neighbors': 5}                1           0.542857   \n",
       "1                10  {'n_neighbors': 10}                2           0.542857   \n",
       "2                20  {'n_neighbors': 20}                3           0.528571   \n",
       "3                50  {'n_neighbors': 50}                4           0.528571   \n",
       "\n",
       "   split0_train_score  split1_test_score       ...         split2_test_score  \\\n",
       "0            0.655039           0.573529       ...                  0.590909   \n",
       "1            0.589147           0.573529       ...                  0.575758   \n",
       "2            0.573643           0.544118       ...                  0.560606   \n",
       "3            0.562016           0.544118       ...                  0.545455   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0            0.637405           0.650794            0.611321   \n",
       "1            0.576336           0.587302            0.569811   \n",
       "2            0.561069           0.587302            0.558491   \n",
       "3            0.557252           0.571429            0.550943   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.606557            0.647940      0.000490        0.001625   \n",
       "1           0.606557            0.591760      0.000400        0.000400   \n",
       "2           0.590164            0.561798      0.000400        0.000748   \n",
       "3           0.590164            0.546816      0.000633        0.000400   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.035909         0.016149  \n",
       "1        0.020829         0.010889  \n",
       "2        0.023971         0.005667  \n",
       "3        0.021765         0.005384  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters{'n_neighbors': 5}\n",
      "Best score 0.591\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters{}'.format(grid_search.best_params_))\n",
    "print('Best score {:.3f}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN classifcation\n",
      "Train score: 0.643\n",
      "Test score: 0.609\n"
     ]
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_clf.fit(X_train,y_train)\n",
    "\n",
    "print('KNN classifcation')\n",
    "print('Train score: {0:0.3f}'.format(knn_clf.score(X_train, y_train)))\n",
    "print('Test score: {0:0.3f}'.format(knn_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2']}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(recall_score, average=weighted), verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lreg = LogisticRegression()\n",
    "param_grid = {'penalty':['l1', 'l2']}\n",
    "\n",
    "grid_search = GridSearchCV(lreg, param_grid, cv = 5 ,scoring=recall_score, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.065404</td>\n",
       "      <td>0.011201</td>\n",
       "      <td>0.719512</td>\n",
       "      <td>0.775153</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'penalty': 'l1'}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.779070</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.770992</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.762264</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.005239</td>\n",
       "      <td>0.020401</td>\n",
       "      <td>0.042488</td>\n",
       "      <td>0.008137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.071204</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.713415</td>\n",
       "      <td>0.825435</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'penalty': 'l2'}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.661765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.828244</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.815094</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.835206</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.035908</td>\n",
       "      <td>0.006729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.065404         0.011201         0.719512          0.775153   \n",
       "1       0.071204         0.001400         0.713415          0.825435   \n",
       "\n",
       "  param_penalty             params  rank_test_score  split0_test_score  \\\n",
       "0            l1  {'penalty': 'l1'}                1           0.700000   \n",
       "1            l2  {'penalty': 'l2'}                2           0.714286   \n",
       "\n",
       "   split0_train_score  split1_test_score       ...         split2_test_score  \\\n",
       "0            0.779070           0.676471       ...                  0.742424   \n",
       "1            0.821705           0.661765       ...                  0.742424   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0            0.770992           0.793651            0.762264   \n",
       "1            0.828244           0.761905            0.815094   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.688525            0.786517      0.005239        0.020401   \n",
       "1           0.688525            0.835206      0.002482        0.000490   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.042488         0.008137  \n",
       "1        0.035908         0.006729  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters{'penalty': 'l1'}\n",
      "Best score 0.720\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters{}'.format(grid_search.best_params_))\n",
    "print('Best score {:.3f}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Train score: 0.780\n",
      "Test score: 0.727\n"
     ]
    }
   ],
   "source": [
    "lreg_clf = LogisticRegression(penalty = 'l1')\n",
    "lreg_clf.fit(X_train,y_train)\n",
    "\n",
    "print('Logistic Regression')\n",
    "print('Train score: {0:0.3f}'.format(lreg_clf.score(X_train, y_train)))\n",
    "print('Test score: {0:0.3f}'.format(lreg_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Linear Supprt Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.01, 0.1, 1, 10]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(recall_score, average=weighted), verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lin = LinearSVC()\n",
    "\n",
    "param_grid = {'C':[0.01, 0.1, 1, 10]}\n",
    "\n",
    "grid_search = GridSearchCV(lin, param_grid, cv = 5, scoring=recall_score, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters{'C': 0.1}\n",
      "Best score 0.716\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters{}'.format(grid_search.best_params_))\n",
    "print('Best score {:.3f}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Supprt Vector Machine\n",
      "Train score: 0.829\n",
      "Test score: 0.736\n"
     ]
    }
   ],
   "source": [
    "lin_clf = LinearSVC(C=0.1).fit(X_train, y_train)\n",
    "print('Linear Supprt Vector Machine')\n",
    "print('Train score: {:.3f}'.format(lin_clf.score(X_train, y_train)))\n",
    "print('Test score: {:.3f}'.format(lin_clf.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Kerenilzed Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'kernel': ('rbf', 'sigmoid', 'linear'), 'C': [0.01, 0.1, 1, 10], 'gamma': [0.01, 0.1, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(recall_score, average=weighted), verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "param_grid = {'kernel':('rbf', 'sigmoid','linear'),\n",
    "              'C':[0.01, 0.1, 1, 10],\n",
    "              'gamma':[0.01, 0.1, 1, 10]}\n",
    "\n",
    "grid_search = GridSearchCV(svc, param_grid, cv = 5, scoring=recall_score, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters{'C': 1, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "Best score 0.720\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters{}'.format(grid_search.best_params_))\n",
    "print('Best score {:.3f}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine with kernels\n",
      "Train score: 0.881\n",
      "Test score: 0.755\n"
     ]
    }
   ],
   "source": [
    "svc_clf = SVC(C=1, gamma=0.01,kernel='linear').fit(X_train, y_train)\n",
    "print('Support Vector Machine with kernels')\n",
    "print('Train score: {:.3f}'.format(svc_clf.score(X_train, y_train)))\n",
    "print('Test score: {:.3f}'.format(svc_clf.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': range(1, 20)}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(recall_score, average=weighted), verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "param_grid = {'max_depth':range(1,20)}\n",
    "\n",
    "grid_search = GridSearchCV(dt, param_grid, cv=5,scoring=recall_score,  return_train_score = True)\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters{'max_depth': 5}\n",
      "Best score 0.698\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters{}'.format(grid_search.best_params_))\n",
    "print('Best score {:.3f}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Train score: 0.811\n",
      "Test score: 0.718\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(max_depth = 5).fit(X_train,y_train)\n",
    "print('Decision Tree')\n",
    "print('Train score: {:.3f}'.format(dt_clf.score(X_train, y_train)))\n",
    "print('Test score: {:.3f}'.format(dt_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': range(1, 20)}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(recall_score, average=weighted), verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "param_grid = {'max_depth':range(1,20)}\n",
    "\n",
    "grid_search = GridSearchCV(rf,param_grid, cv= 5, scoring=recall_score, return_train_score = True)\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters{'max_depth': 13}\n",
      "Best score 0.723\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters{}'.format(grid_search.best_params_))\n",
    "print('Best score {:.3f}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Train score: 0.960\n",
      "Test score: 0.682\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(max_depth = 14).fit(X_train,y_train)\n",
    "print('Random Forest')\n",
    "print('Train score: {:.3f}'.format(rf_clf.score(X_train, y_train)))\n",
    "print('Test score: {:.3f}'.format(rf_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.738\n",
      "Test score: 0.682\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "hard_voting_clf = VotingClassifier(estimators=[('dt', dt_clf),('knn', knn_clf),('lr',lreg_clf)], voting = 'hard')\n",
    "hard_voting_clf.fit(X_train, y_train)\n",
    "print('Train score: {0:0.3f}'.format(hard_voting_clf.score(X_train, y_train)))\n",
    "print('Test score: {0:0.3f}'.format(hard_voting_clf.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.81\n",
      "Test score: 0.72\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "soft_voting_clf = VotingClassifier(estimators=[('dt', dt_clf),('knn', knn_clf),('lr',lreg_clf)], voting = 'soft')\n",
    "soft_voting_clf.fit(X_train, y_train)\n",
    "print('Train score: {0:0.2f}'.format(soft_voting_clf.score(X_train, y_train)))\n",
    "print('Test score: {0:0.2f}'.format(soft_voting_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_total= pd.concat([pd.DataFrame(X_train),pd.DataFrame(X_test)])\n",
    "y_total =pd.concat([pd.DataFrame(y_train),pd.DataFrame(y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier 0.0936073059361 \n",
      "\n",
      "LogisticRegression 0.0570776255708 \n",
      "\n",
      "LinearSVC 0.0114155251142 \n",
      "\n",
      "SVC 0.100456621005 \n",
      "\n",
      "DecisionTreeClassifier 0.0388127853881 \n",
      "\n",
      "RandomForestClassifier 0.0365296803653 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "for clf in (knn, lreg, lin, svc, dt, rf):\n",
    "    bag_clf = BaggingClassifier(clf, n_estimators=100,bootstrap=True, n_jobs=-1, oob_score=True, random_state=10)\n",
    "    bag_clf.fit(X_total, y_total)\n",
    "    print(clf.__class__.__name__, bag_clf.oob_score_, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.681818181818 \n",
      "\n",
      "LinearSVC 0.736363636364 \n",
      "\n",
      "SVC 0.572727272727 \n",
      "\n",
      "DecisionTreeClassifier 0.663636363636 \n",
      "\n",
      "RandomForestClassifier 0.727272727273 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "for clf in (lreg, lin, svc, dt, rf):    \n",
    "    ada_clf = AdaBoostClassifier(clf, n_estimators=200, algorithm=\"SAMME\", learning_rate=0.5, random_state=10)\n",
    "    ada_clf.fit(X_train, y_train)\n",
    "    print(clf.__class__.__name__, ada_clf.score(X_test,y_test),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Model with Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA().fit(X_train)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum >= 0.95) + 1\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative sum of Variance\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa431a70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Cumulative sum of Variance')\n",
    "plt.plot(cumsum)\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 80)\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "X_test_reduced = pca.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. KNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters{'n_neighbors': 5}\n",
      "Best score 0.601\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_neighbors':[1,5,10,15,20]}\n",
    "\n",
    "grid_search = GridSearchCV(knn, param_grid, cv = 5,scoring=recall_score, return_train_score=True)\n",
    "grid_search.fit(X_train_reduced, y_train)\n",
    "\n",
    "print('Best parameters{}'.format(grid_search.best_params_))\n",
    "print('Best score {:.3f}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN classifcation\n",
      "Train score: 0.643\n",
      "Test score: 0.555\n"
     ]
    }
   ],
   "source": [
    "knn_clf_pca = KNeighborsClassifier(n_neighbors=5).fit(X_train_reduced, y_train)\n",
    "print('KNN classifcation')\n",
    "print('Train score: {:.3f}'.format(knn_clf_pca.score(X_train_reduced, y_train)))\n",
    "print('Test score: {:.3f}'.format(knn_clf_pca.score(X_test_reduced, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Logistics regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters{'penalty': 'l1'}\n",
      "Best score 0.713\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'penalty':['l1','l2']}\n",
    "\n",
    "grid_search = GridSearchCV(lreg, param_grid, cv = 5,scoring=recall_score, return_train_score=True)\n",
    "grid_search.fit(X_train_reduced, y_train)\n",
    "\n",
    "print('Best parameters{}'.format(grid_search.best_params_))\n",
    "print('Best score {:.3f}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Train score: 0.808\n",
      "Test score: 0.536\n"
     ]
    }
   ],
   "source": [
    "lreg_clf_pca = LogisticRegression(penalty = 'l2').fit(X_train_reduced, y_train)\n",
    "\n",
    "print('Logistic Regression')\n",
    "print('Train score: {:.3f}'.format(lreg_clf_pca.score(X_train_reduced, y_train)))\n",
    "print('Test score: {:.3f}'.format(lreg_clf_pca.score(X_test_reduced, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters{'C': 0.1}\n",
      "Best score 0.716\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C':[0.01, 0.1, 1, 10]}\n",
    "\n",
    "grid_search = GridSearchCV(lin, param_grid, cv = 5, scoring=recall_score,return_train_score=True)\n",
    "grid_search.fit(X_train_reduced, y_train)\n",
    "\n",
    "print('Best parameters{}'.format(grid_search.best_params_))\n",
    "print('Best score {:.3f}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Supprt Vector Machine\n",
      "Train score: 0.799\n",
      "Test score: 0.536\n"
     ]
    }
   ],
   "source": [
    "lin_clf_pca = LinearSVC(C=0.1).fit(X_train_reduced, y_train)\n",
    "print('Linear Supprt Vector Machine')\n",
    "print('Train score: {:.3f}'.format(lin_clf_pca.score(X_train_reduced, y_train)))\n",
    "print('Test score: {:.3f}'.format(lin_clf_pca.score(X_test_reduced,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Kerenilzed Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters{'C': 1, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "Best score 0.716\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'kernel':('rbf', 'sigmoid','linear'),\n",
    "              'C':[0.01, 0.1, 1, 10],\n",
    "              'gamma':[0.01, 0.1, 1, 10]}\n",
    "\n",
    "grid_search = GridSearchCV(svc, param_grid, cv = 5,scoring=recall_score, return_train_score=True)\n",
    "grid_search.fit(X_train_reduced, y_train)\n",
    "\n",
    "print('Best parameters{}'.format(grid_search.best_params_))\n",
    "print('Best score {:.3f}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine with kernels\n",
      "Train score: 0.838\n",
      "Test score: 0.555\n"
     ]
    }
   ],
   "source": [
    "sv_clf_pca = SVC(C=10, gamma=0.1,kernel='sigmoid').fit(X_train_reduced, y_train)\n",
    "print('Support Vector Machine with kernels')\n",
    "print('Train score: {:.3f}'.format(sv_clf_pca.score(X_train_reduced, y_train)))\n",
    "print('Test score: {:.3f}'.format(sv_clf_pca.score(X_test_reduced,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters{'max_depth': 1}\n",
      "Best score 0.576\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth':range(1,20)}\n",
    "\n",
    "grid_search = GridSearchCV(dt, param_grid, cv=5, scoring=recall_score,return_train_score = True)\n",
    "grid_search.fit(X_train_reduced,y_train)\n",
    "\n",
    "print('Best parameters{}'.format(grid_search.best_params_))\n",
    "print('Best score {:.3f}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Train score: 0.588\n",
      "Test score: 0.473\n"
     ]
    }
   ],
   "source": [
    "dt_clf_pca = DecisionTreeClassifier(max_depth = 1).fit(X_train_reduced,y_train)\n",
    "print('Decision Tree')\n",
    "print('Train score: {:.3f}'.format(dt_clf_pca.score(X_train_reduced, y_train)))\n",
    "print('Test score: {:.3f}'.format(dt_clf_pca.score(X_test_reduced, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters{'max_depth': 17}\n",
      "Best score 0.591\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth':range(1,20)}\n",
    "\n",
    "grid_search = GridSearchCV(rf, param_grid, cv= 5,scoring=recall_score, return_train_score = True)\n",
    "grid_search.fit(X_train_reduced,y_train)\n",
    "\n",
    "print('Best parameters{}'.format(grid_search.best_params_))\n",
    "print('Best score {:.3f}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Train score: 0.774\n",
      "Test score: 0.509\n"
     ]
    }
   ],
   "source": [
    "rf_clf_pca = RandomForestClassifier(max_depth = 6).fit(X_train_reduced,y_train)\n",
    "print('Random Forest')\n",
    "print('Train score: {:.3f}'.format(rf_clf_pca.score(X_train_reduced, y_train)))\n",
    "print('Test score: {:.3f}'.format(rf_clf_pca.score(X_test_reduced, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 7. Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.750\n",
      "Test score: 0.536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "hard_voting_clf = VotingClassifier(estimators=[('dt', dt_clf),('knn', knn_clf),('lr',lreg_clf)], voting = 'hard')\n",
    "hard_voting_clf.fit(X_train_reduced, y_train)\n",
    "print('Train score: {0:0.3f}'.format(hard_voting_clf.score(X_train_reduced, y_train)))\n",
    "print('Test score: {0:0.3f}'.format(hard_voting_clf.score(X_test_reduced, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.78\n",
      "Test score: 0.53\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "soft_voting_clf = VotingClassifier(estimators=[('dt', dt_clf),('knn', knn_clf),('lr',lreg_clf)], voting = 'soft')\n",
    "soft_voting_clf.fit(X_train_reduced, y_train)\n",
    "print('Train score: {0:0.2f}'.format(soft_voting_clf.score(X_train_reduced, y_train)))\n",
    "print('Test score: {0:0.2f}'.format(soft_voting_clf.score(X_test_reduced, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Bagging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_total_reduced= pd.concat([pd.DataFrame(X_train_reduced),pd.DataFrame(X_test_reduced)])\n",
    "y_total =pd.concat([pd.DataFrame(y_train),pd.DataFrame(y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier 0.0958904109589 \n",
      "\n",
      "LogisticRegression 0.0570776255708 \n",
      "\n",
      "LinearSVC 0.0296803652968 \n",
      "\n",
      "SVC 0.100456621005 \n",
      "\n",
      "DecisionTreeClassifier 0.0799086757991 \n",
      "\n",
      "RandomForestClassifier 0.0981735159817 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "for clf in (knn, lreg, lin, svc, dt, rf):\n",
    "    bag_clf = BaggingClassifier(clf, n_estimators=100,bootstrap=True, n_jobs=-1, oob_score=True, random_state=10)\n",
    "    bag_clf.fit(X_total_reduced, y_total)\n",
    "    print(clf.__class__.__name__, bag_clf.oob_score_, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.427272727273 \n",
      "\n",
      "LinearSVC 0.490909090909 \n",
      "\n",
      "SVC 0.572727272727 \n",
      "\n",
      "DecisionTreeClassifier 0.390909090909 \n",
      "\n",
      "RandomForestClassifier 0.572727272727 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "for clf in (lreg, lin, svc, dt, rf):    \n",
    "    ada_clf = AdaBoostClassifier(clf, n_estimators=200, algorithm=\"SAMME\", learning_rate=0.5, random_state=10)\n",
    "    ada_clf.fit(X_train_reduced, y_train)\n",
    "    print(clf.__class__.__name__, ada_clf.score(X_test_reduced,y_test),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. SUMMARY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In generally, baggind and boosting methods has a better prediction than single classfier. \n",
    "And PCA is a good way to reduce the demension of features and reduce the operating time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
